# -*- coding: utf-8 -*-
"""Topic Modelling.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/10Y8ZJ3kFAWUNhjn926_UdCxodlsTXhTk
"""

import requests
from bs4 import BeautifulSoup

url = ['https://www.wsws.org/en/articles/2023/02/17/upfo-f17.html',
       'https://thewire.in/environment/india-had-eight-worst-air-pollution-in-2022-report']

       
headers={'user-agent':'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/106.0.0.0 Safari/537.36'}
data=[]

#url1
response0 = requests.get(url[0],headers=headers)
soup0 = BeautifulSoup(response0.content, 'html.parser')
content = soup0.find('div',class_='content georgia _avenir f5 f4-m f4-l f5-p lh-copy _measure-wide').text
data.append(content)

#url2
response1 = requests.get(url[1],headers=headers)
soup1 = BeautifulSoup(response1.content, 'html.parser')
content1 = soup1.find('div',class_='grey-text').text
data.append(content1)

import pandas as pd
df=pd.DataFrame({"Article":data})

!pip install -q num2words
import nltk
from nltk.corpus import stopwords
from nltk.tokenize import word_tokenize
from nltk.stem import WordNetLemmatizer
from nltk.stem.porter import PorterStemmer
import string
import re
from num2words import num2words

nltk.download('punkt')
nltk.download('stopwords')
nltk.download('wordnet')
nltk.download('omw-1.4')

def preprocess(text):

    # Convert text to lowercase
    text = text.lower()

    # Remove punctuation
    text = text.translate(str.maketrans("", "", string.punctuation))

    # Tokenize text
    tokens = word_tokenize(text)
    
    # Remove stopwords
    stop_words = set(stopwords.words('english'))
    filtered_tokens = [token for token in tokens if token not in stop_words]

    # Lemmatize words
    lemmatizer = WordNetLemmatizer()
    lemmatized_tokens = [lemmatizer.lemmatize(token) for token in filtered_tokens]
    
    # Join tokens back into a string
    preprocessed_text = ' '.join(lemmatized_tokens)
    
    return preprocessed_text

df['Preprocessed'] = df['Article'].apply(preprocess)
df