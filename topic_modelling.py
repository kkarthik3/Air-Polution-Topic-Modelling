# -*- coding: utf-8 -*-
"""Topic Modelling.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/10Y8ZJ3kFAWUNhjn926_UdCxodlsTXhTk
"""

import requests
from bs4 import BeautifulSoup

url = ['https://www.wsws.org/en/articles/2023/02/17/upfo-f17.html',
       'https://thewire.in/environment/india-had-eight-worst-air-pollution-in-2022-report']

       
headers={'user-agent':'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/106.0.0.0 Safari/537.36'}
data=[]

#url1
response0 = requests.get(url[0],headers=headers)
soup0 = BeautifulSoup(response0.content, 'html.parser')
content = soup0.find('div',class_='content georgia _avenir f5 f4-m f4-l f5-p lh-copy _measure-wide').text
data.append(content)

#url2
response1 = requests.get(url[1],headers=headers)
soup1 = BeautifulSoup(response1.content, 'html.parser')
content1 = soup1.find('div',class_='grey-text').text
data.append(content1)

# Import necessary libraries
import gensim
from gensim import corpora
import pyLDAvis.gensim_models
import matplotlib.pyplot as plt
from nltk.stem import WordNetLemmatizer
from nltk.corpus import stopwords
import nltk
nltk.download('punkt')
nltk.download('stopwords')
nltk.download('wordnet')
nltk.download('omw-1.4')

# Define a function for topic modeling
def topic_modeling(text, num_topics=5, num_words=10):
    # Tokenize the text
    text_tokens = gensim.utils.simple_preprocess(text, deacc=True, min_len=3)
    print(text_tokens)
    
    # Remove stopwords
    stop_words = set(stopwords.words('english'))
    filtered_tokens = [token for token in text_tokens if token not in stop_words]

    # Lemmatize words
    lemmatizer = WordNetLemmatizer()
    lemmatized_tokens = [lemmatizer.lemmatize(token) for token in filtered_tokens]

    # Create a dictionary from the tokenized text
    dictionary = corpora.Dictionary([lemmatized_tokens])
    
    # Create a bag of words from the dictionary
    bow_corpus = [dictionary.doc2bow(lemmatized_tokens)]
    
    # Train the LDA model
    lda_model = gensim.models.LdaModel(bow_corpus, num_topics=num_topics, id2word=dictionary, passes=10)
    
    # Print the top words for each topic
    for idx, topic in lda_model.print_topics(num_topics=num_topics, num_words=num_words):
        print("Topic: {} \nWords: {}".format(idx, topic))
    
    # Visualize the topics
    pyLDAvis.enable_notebook()
    vis = pyLDAvis.gensim_models.prepare(lda_model, bow_corpus, dictionary, R=30)
    return vis

# Perform topic modeling and visualization
topic_modeling(content)